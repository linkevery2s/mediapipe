<!DOCTYPE HTML>
<html lang="ja">
<title>MediaPipe Hand</title>

<head prefix="og: http://ogp.me/ns# fb: http://ogp.me/ns/fb# article: http://ogp.me/ns/article#">
  <meta charset="UTF-8" name="viewport"
    content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=no">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta property="og:title" content="MediaPipe Hand" />
  <meta property="og:type" content="website" />
  <meta property="og:image" content="./ogp.png" />
  <meta name="description"
    content="GoogleのAIライブラリ「MediaPipe」を使ってみました。Handでは、カメラから手を認識してくれます。カメラを通して手を認識すると、関節の骨組みが表示されます。スポーツ・医療現場での利用を考えていきます。" />
  <meta name="twitter:card" content="summary_large_image">
  <meta name="twitter:title" content="MediaPipe Hand" />
  <meta name="twitter:image" content="./ogp.png" />
  <meta name="author" content="仁志">
  <meta name="keywords" content="MediaPipe, hand, Google, MediaPipe Hand" />
  <style>
    html {
      width: 100%;
      height: 100%;
      margin: 0;
      padding: 0;
    }

    video {
      clear: both;
      display: block;
      /*
      transform: rotateY(180deg);
      -webkit-transform: rotateY(180deg);
      -moz-transform: rotateY(180deg);
      */
      width: 100%;
      margin: 0;
      padding: 0;
    }

    .videoView {
      width: 100%;
      max-width: 700px;
      margin: 0;
      padding: 0;
      position: absolute;
      text-align: center;
      top: 0;
      left: 50%;
      transform: translateX(-50%);
      -webkit-transform: translateX(-50%);
      -ms-transform: translateX(-50%);
    }

    #webcamButton {
      margin-bottom: 15px;
      cursor: pointer;
      padding: 1rem;
      background-color: #ffffff;
      color: brown;
      border-radius: 3em;
      font-weight: 900;
    }

    #webcamera {
      position: relative;
      margin-top: 2rem;
      margin-bottom: 3rem;
    }

    .canvas {
      z-index: 1;
      position: absolute;
      pointer-events: none;
      padding: 0;
      margin: 0;
    }

    .output_canvas {
      width: 100%;
      padding: 0;
      margin: 0;
    }

    #abstract {
      text-align: left;
      background-color: rgba(255, 255, 255, 0.7);
      padding: 2rem;
      margin: 1rem;
      max-width: 700px;
      border-radius: 1em;
    }

    body {
      background: #824880;
      width: 100%;
      height: 100%;
      padding: 0;
      margin: 0;

    }

    #particles-js {
      position: relative;
      width: 100%;
      height: 95%;
      background-size: cover;
      background-repeat: no-repeat;
      padding: 0;
      margin: 0;
    }

    h1 {
      color: #ffffff;
    }

    #footer {
      margin: 15px 0 0 0;
      padding: 2px 0 2px 0;
      text-align: center;
      background: #000000;
      color: #ffffff;
      bottom: 0;
    }

    #footer a {
      text-decoration: none;
      color: #ffffff;
      border-bottom: 1px dotted #ffffff;
    }
  </style>
</head>

<body>

  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/drawing_utils/drawing_utils.js" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/hands/hands.js" crossorigin="anonymous"></script>

  <body>

    <div id="particles-js">
    </div>

    <div id="liveView" class="videoView">

      <h1>MediaPipe Hand</h1>

      <span id="webcamButton">
        カメラをONにする
      </span>
      <div id="webcamera">
        <video id="webcam" style="position: absolute；" autoplay playsinline></video>
        <canvas class="output_canvas" id="output_canvas" style="position: absolute; left: 0px; top: 0px;"></canvas>
      </div>

      <div id="abstract">
        GoogleのAIライブラリ「MediaPipe」を使ってみました。Handでは、カメラから手を認識してくれます。カメラを通して手を認識すると、関節の骨組みが表示されます。スポーツ・医療現場での利用を考えていきます。

        <div id="footer">
          &copy; 2023 仁志、<a href="https://creativecommons.org/licenses/by/4.0/deed.ja" target="_blank">CC BY 4.0</a>
        </div>
      </div>

    </div>



    <script type="module">
      import { HandLandmarker, FilesetResolver } from "https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0";

      let handLandmarker = undefined;
      let runningMode = "IMAGE";
      const video = document.getElementById("webcam");
      const canvasElement = document.getElementById("output_canvas");
      const canvasCtx = canvasElement.getContext("2d");
      const enableWebcamButton = document.getElementById("webcamButton");
      let lastVideoTime = -1;
      let results = undefined;

      const createHandLandmarker = async () => {
        const vision = await FilesetResolver.forVisionTasks("https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm");
        handLandmarker = await HandLandmarker.createFromOptions(vision, {
          baseOptions: {
            modelAssetPath: `https://storage.googleapis.com/mediapipe-models/hand_landmarker/hand_landmarker/float16/1/hand_landmarker.task`,
            delegate: "GPU"
          },
          runningMode: runningMode,
          numHands: 2
        });

      };
      createHandLandmarker();

      let predictWebcam = async () => {
        canvasElement.style.width = video.videoWidth;
        canvasElement.style.height = video.videoHeight;
        canvasElement.width = video.videoWidth;
        canvasElement.height = video.videoHeight;

        if (runningMode === "IMAGE") {
          runningMode = "VIDEO";
          await handLandmarker.setOptions({ runningMode: "VIDEO" });
        }
        let startTimeMs = performance.now();
        if (lastVideoTime !== video.currentTime) {
          lastVideoTime = video.currentTime;
          results = handLandmarker.detectForVideo(video, startTimeMs);
        }
        canvasCtx.save();
        canvasCtx.clearRect(0, 0, canvasElement.width, canvasElement.height);
        if (results.landmarks) {
          for (const landmarks of results.landmarks) {

            drawConnectors(canvasCtx, landmarks, HAND_CONNECTIONS, { color: "#00FF00", lineWidth: 5 });
            drawLandmarks(canvasCtx, landmarks, { color: "#FF0000", lineWidth: 2 });

          }
        }
        canvasCtx.restore();

        window.requestAnimationFrame(predictWebcam);

      }

      let enableCam = (event) => {
        if (!handLandmarker) {
          console.log("Wait! objectDetector not loaded yet.");
          return;
        }

        const constraints = {
          video: { facingMode: "environment" }
        };
        // Activate the webcam stream.
        navigator.mediaDevices.getUserMedia(constraints).then((stream) => {
          video.srcObject = stream;
          video.addEventListener("loadeddata", predictWebcam);
        });
      }

      enableWebcamButton.addEventListener("click", enableCam);

    </script>

    <script type="text/javascript" src="js/particles.min.js"></script>
    <script type="text/javascript" src="js/app.js"></script>

  </body>

</html>